{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge and Data: Practical Assignment 3 \n",
    "## RDF Data, RDFS knowledge and inferencing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR NAME: Thomas Norton\n",
    "\n",
    "YOUR VUNetID: tnn281\n",
    "\n",
    "*(If you do not provide your name and VUNetID we will not accept your submission).* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "At the end of this exercise you should be able to:\n",
    "\n",
    "1. Access local an external data via SPARQL both from within a python programming environment and stand-alone with a GUI, such as [YASGUI](https://yasgui.triply.cc/), and this way integrate data from different sources  \n",
    "2. Model your own first knowledge base, in this case an RDF Schema knowledge graph\n",
    "3. Implement inference rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this Notebook step-by-step. \n",
    "\n",
    "Of course, you can do the exercises in any Programming Editor of your liking. \n",
    "But you do not have to. Feel free to simply write code in the Notebook. When \n",
    "everythink is filled in and works, safe the Notebook and submit it \n",
    "as a Jupyter Notebook, i.e. with an ipynb extension. Please use as name of the \n",
    "Notebook your studentID+Assignment3.ipynb.  \n",
    "\n",
    "Other than in courses dedicated to programming we will not evaluate the style\n",
    "of the programs. But we will test your programs on other data than we provide, \n",
    "and your program should give the correct answers to those test-data as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start, you need to:\n",
    "\n",
    "- **Install the *rdflib* Python package:** *pip install rdflib* (should already be installed from the previous assignment)\n",
    "- **Install the *SPARQLWrapper* Python package:** *pip install SPARQLWrapper*\n",
    "- **Install the free edition of the GraphDB Triplestore:** please follow this short [GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md). \n",
    "\n",
    "Then, add the file example-from-slides.ttl to a newly created database, say called assignment-3. \n",
    "\n",
    "**Note that you should have an active internet connection to run the code in this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SPARQLWrapper in c:\\python310\\lib\\site-packages (2.0.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.2.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: rdflib>=6.1.1 in c:\\python310\\lib\\site-packages (from SPARQLWrapper) (6.2.0)\n",
      "Requirement already satisfied: pyparsing in c:\\python310\\lib\\site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from rdflib>=6.1.1->SPARQLWrapper) (58.1.0)\n",
      "Requirement already satisfied: isodate in c:\\python310\\lib\\site-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
      "Requirement already satisfied: six in c:\\python310\\lib\\site-packages (from isodate->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# install library\n",
    "%pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: (3 points) Integrate Local and External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can integrate SPARQL queries into your Python code by using the *RDFLib* and *SPARQLWrapper* libraries. \n",
    "\n",
    "The following code accesses the DBPedia knowledge graph using its SPARQL endpoint, and returns the result of the SPARQL query requesting all the labels asserted to Amsterdam (test it!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amsterdam\n",
      "أمستردام\n",
      "حكومة أمستردام\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Άμστερνταμ (δήμος)\n",
      "Άμστερνταμ\n",
      "Amsterdam\n",
      "Amsterdamo\n",
      "Ámsterdam\n",
      "Amsterdam\n",
      "Amsterdam (commune)\n",
      "Amsterdam\n",
      "Amstardam\n",
      "Amsterdam\n",
      "アムステルダム\n",
      "Amsterdam\n",
      "암스테르담\n",
      "Amsterdam (gemeente)\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Amesterdão\n",
      "Амстердам\n",
      "Amsterdam\n",
      "Амстердам\n",
      "阿姆斯特丹\n"
     ]
    }
   ],
   "source": [
    "# This code only works if you are online\n",
    "\n",
    "from rdflib import Graph, RDF, RDFS, Namespace, Literal, URIRef\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?cityName\n",
    "    WHERE { \n",
    "        <http://dbpedia.org/resource/Amsterdam> rdfs:label ?cityName \n",
    "    }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"cityName\"][\"value\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is now the following:\n",
    "1. Write a SPARQL query that extracts all the cities from your local knowledge graph (constructed by loading the file example-from-slides.ttl) \n",
    "2. Find the number of inhabitants of these cities and the longitude and latitude information (if available) from DBPedia.\n",
    "3. Merge the triples from example-from-slides.ttl with the information extracted from DBpedia + Save all these triples into a new file 'extended-example.ttl' + Print all triples in Turtle Syntax.\n",
    "\n",
    "For your convenience, we already wrote the following functions that might be useful to complete this task. \n",
    "In addition, we have loaded and printed the 'example-from-slides.ttl' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:Netherlands a ex:Country ;\n",
      "    ex:contains ex:Ijsselmeer ;\n",
      "    ex:containsCity ex:Rotterdam ;\n",
      "    ex:hasCapital ex:Amsterdam ;\n",
      "    ex:hasName \"The Netherlands\" ;\n",
      "    ex:neighbours ex:Belgium .\n",
      "\n",
      "ex:hasCapital rdfs:range ex:Capital ;\n",
      "    rdfs:subPropertyOf ex:containsCity .\n",
      "\n",
      "ex:neighbours rdfs:subPropertyOf ex:closeBy .\n",
      "\n",
      "ex:Amsterdam a ex:Capital ;\n",
      "    ex:closeBy ex:Germany .\n",
      "\n",
      "ex:Belgium a ex:Country .\n",
      "\n",
      "ex:EuropeanCountry rdfs:subClassOf ex:Country .\n",
      "\n",
      "ex:Germany a ex:EuropeanCountry ;\n",
      "    ex:hasCapital ex:Berlin .\n",
      "\n",
      "ex:closeBy rdfs:domain ex:Location ;\n",
      "    rdfs:range ex:Location .\n",
      "\n",
      "ex:containsCity rdfs:domain ex:Country ;\n",
      "    rdfs:range ex:City ;\n",
      "    rdfs:subPropertyOf ex:contains .\n",
      "\n",
      "ex:Capital rdfs:subClassOf ex:City .\n",
      "\n",
      "ex:City rdfs:subClassOf ex:Location .\n",
      "\n",
      "ex:Country rdfs:subClassOf ex:Location .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, RDF, Namespace, Literal, URIRef, XSD\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "\n",
    "# Loads the data from a certain file given as input in Turtle syntax into the Graph g  \n",
    "# -------------------------\n",
    "def load_graph(graph, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        graph.parse(f, format='turtle')\n",
    "        \n",
    "\n",
    "# Prints a certain graph given as input in Turtle syntax\n",
    "# -------------------------\n",
    "def serialize_graph(myGraph):\n",
    "     print(myGraph.serialize(format='turtle'))\n",
    "        \n",
    "\n",
    "# Saves the Graph g in Turtle syntax to a certain file given as input\n",
    "# -------------------------\n",
    "def save_graph(myGraph, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        myGraph.serialize(filename, format='turtle')\n",
    "        \n",
    "    \n",
    "# Changes the namespace of a certain URI given as input to a DBpedia URI \n",
    "# Example: transformToDBR(\"http://example.com/kad2020/Amsterdam\") returns \"http://dbpedia.org/resource/Amsterdam\"\n",
    "# -------------------------\n",
    "def transformToDBR(uri):\n",
    "    if isinstance(uri, Literal):\n",
    "        # changes the literal to uppercase so that the object with the same name refers to an object and not the string\n",
    "        return uri.upper()\n",
    "    components = g.namespace_manager.compute_qname(uri)\n",
    "    return \"http://dbpedia.org/resource/%s\"%(components[2])\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "g = Graph()\n",
    "load_graph(g, 'example-from-slides.ttl')\n",
    "serialize_graph(g)\n",
    "\n",
    "\n",
    "# Don't forget to run this cell before continuing the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a SPARQL query that finds all the cities in the dataset\n",
    "\n",
    "As you cannot directly use class City, you will have to find those cities in the dataset (example-from-slides.ttl) using implicit information that can be deduced from the domain and ranges of the relations (e.g. things in a hasCapital relation are capitals and a capital is a city, etc.).\n",
    "\n",
    "Save all the cities returned from the SPARQL query into the empty set \"cities\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/Rotterdam\n",
      "http://example.com/kad/Berlin\n",
      "http://example.com/kad/Amsterdam\n"
     ]
    }
   ],
   "source": [
    "cities = set()\n",
    "\n",
    "# Your code here\n",
    "for s,p,o in g:\n",
    "    p = p.split(\"/\")\n",
    "    if p[-1] == 'hasCapital':\n",
    "        cities.add(o)\n",
    "    elif p[-1] == 'containsCity':\n",
    "        cities.add(o)\n",
    "    \n",
    "    \n",
    "for city in cities:\n",
    "    print(city) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For each city, find from DBpedia its longitude & latitude, and its number of inhabitants (if available)\n",
    "\n",
    "Don't forget to adapt the namespace of the cities in your dataset when querying DBpedia, using the above function *transformToDBR(uri)*. Also note that namespaces should never use the *https* protocol.\n",
    "\n",
    "The empty graph h should only contain the triples extracted from DBpedia, but added to the URIs with the 'ex' namespace. \n",
    "An example of a triple in h is the following triple: \n",
    "       \n",
    "       ex:Amsterdam dbo:populationTotal \"872680\"^^xsd:nonNegativeInteger ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dbo: <http://dbpedia.org/ontology/> .\n",
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix geo: <http://www.w3.org/2003/01/geo/wgs84_pos#> .\n",
      "\n",
      "ex:Amsterdam dbo:populationTotal \"872680\" ;\n",
      "    geo:lat \"52.3667\" ;\n",
      "    geo:long \"4.9\" .\n",
      "\n",
      "ex:Berlin dbo:populationTotal \"3769495\" ;\n",
      "    geo:lat \"52.52\" ;\n",
      "    geo:long \"13.405\" .\n",
      "\n",
      "ex:Rotterdam dbo:populationTotal \"651157\" ;\n",
      "    geo:lat \"51.9167\" ;\n",
      "    geo:long \"4.5\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h = Graph()\n",
    "\n",
    "# Your code here\n",
    "ex = Namespace(\"http://example.com/kad/\")\n",
    "geo = Namespace(\"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "dbo = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "h.bind('ex', ex)\n",
    "h.bind('geo', geo)\n",
    "h.bind('dbo', dbo)\n",
    "\n",
    "for city in cities:\n",
    "    old = city\n",
    "    city = transformToDBR(city)\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    qry = \"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "        PREFIX geo: <http://www.w3.org/2003/01/geo/wgs84_pos#>\n",
    "        SELECT DISTINCT ?cityName ?lat ?long ?population\n",
    "        WHERE { \"\"\"\n",
    "    qry = qry + '\\n\\t\\t<' + city + \"> rdfs:label ?cityName .\" + '\\n\\t\\t<' + city + '> geo:lat ?lat .' + '\\n\\t\\t<' + city + '> geo:long ?long .' + '\\n\\t\\tOPTIONAL{\\n\\t\\t<' + city + '> dbo:populationTotal ?population}' + '\\n\\t\\tFILTER langMatches(lang(?cityName),\"en\")\\n\\t}\\n GROUP BY ?cityName'\n",
    "    # i used a filter to get rid of city duplicates in different languages. if these are needed, remove the filter section from the qry string above\n",
    "    sparql.setQuery(qry)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        cityName = (result[\"cityName\"][\"value\"])\n",
    "        cityLat = (result[\"lat\"][\"value\"])\n",
    "        cityLong = (result[\"long\"][\"value\"])\n",
    "        cityPop = (result[\"population\"][\"value\"])\n",
    "        h.add((old, geo.lat, Literal(cityLat)))\n",
    "        h.add((old, geo.long, Literal(cityLong)))\n",
    "        if cityPop:\n",
    "            h.add((old, dbo.populationTotal, Literal(cityPop)))\n",
    "        \n",
    "serialize_graph(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save your results\n",
    "\n",
    "- Merge the triples from example-from-slides.ttl with the information extracted from DBpedia\n",
    "- Save all these triples into a new file 'extended-example.ttl'\n",
    "- Print all triples in Turtle Syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dbo: <http://dbpedia.org/ontology/> .\n",
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix geo: <http://www.w3.org/2003/01/geo/wgs84_pos#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:Netherlands a ex:Country ;\n",
      "    ex:contains ex:Ijsselmeer ;\n",
      "    ex:containsCity ex:Rotterdam ;\n",
      "    ex:hasCapital ex:Amsterdam ;\n",
      "    ex:hasName \"The Netherlands\" ;\n",
      "    ex:neighbours ex:Belgium .\n",
      "\n",
      "ex:hasCapital rdfs:range ex:Capital ;\n",
      "    rdfs:subPropertyOf ex:containsCity .\n",
      "\n",
      "ex:neighbours rdfs:subPropertyOf ex:closeBy .\n",
      "\n",
      "ex:Amsterdam a ex:Capital ;\n",
      "    dbo:populationTotal \"872680\" ;\n",
      "    ex:closeBy ex:Germany ;\n",
      "    geo:lat \"52.3667\" ;\n",
      "    geo:long \"4.9\" .\n",
      "\n",
      "ex:Belgium a ex:Country .\n",
      "\n",
      "ex:Berlin dbo:populationTotal \"3769495\" ;\n",
      "    geo:lat \"52.52\" ;\n",
      "    geo:long \"13.405\" .\n",
      "\n",
      "ex:EuropeanCountry rdfs:subClassOf ex:Country .\n",
      "\n",
      "ex:Germany a ex:EuropeanCountry ;\n",
      "    ex:hasCapital ex:Berlin .\n",
      "\n",
      "ex:Rotterdam dbo:populationTotal \"651157\" ;\n",
      "    geo:lat \"51.9167\" ;\n",
      "    geo:long \"4.5\" .\n",
      "\n",
      "ex:closeBy rdfs:domain ex:Location ;\n",
      "    rdfs:range ex:Location .\n",
      "\n",
      "ex:containsCity rdfs:domain ex:Country ;\n",
      "    rdfs:range ex:City ;\n",
      "    rdfs:subPropertyOf ex:contains .\n",
      "\n",
      "ex:Capital rdfs:subClassOf ex:City .\n",
      "\n",
      "ex:City rdfs:subClassOf ex:Location .\n",
      "\n",
      "ex:Country rdfs:subClassOf ex:Location .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "h2 = Graph()\n",
    "h2 = g + h\n",
    "\n",
    "serialize_graph(h2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: (3 points)  Implement Basic Inferencing Rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we showed that the RDFS inference rules can be used to infer new knowledge. For example, infer class membership based on rdfs:domain or infer relationships between subjects and objects based on rdfs:subPropertyOf. \n",
    "\n",
    "Create rules to inference class membership based on the RDF Schema language features \n",
    "*\tFor example: infer that an instance belongs to a class because of domain and range restrictions\n",
    "*\tFor example: infer that an instance belongs to a (super)class because it also belongs to a subclass\n",
    "\n",
    "We implemented the rdfs2 rule. You should implement the 5 following remaining rules:  \n",
    "\n",
    "*     (rdfs2) If G contains the triples (aaa rdfs:domain xxx.) and (uuu aaa yyy.)  then infer the triple (uuu rdf:type xxx.)\n",
    "*     (rdfs3) If G contains the triples (aaa rdfs:range xxx.) and (uuu aaa vvv.) then infer the triple (vvv rdf:type xxx .)\n",
    "*     (rdfs5) If G contains the triples (uuu rdfs:subPropertyOf vvv.) and (vvv rdfs:subPropertyOf xxx.) then infer the triple (uuu rdfs:subPropertyOf xxx.) \n",
    "*     (rdfs7) If G contains the triples (aaa rdfs:subPropertyOf bbb.) and (uuu aaa yyy.) then infer the triple (uuu bbb yyy) \n",
    "*     (rdfs9) If G contains the triples (uuu rdfs:subClassOf xxx.) and (vvv rdf:type uuu.) then infer the triple (vvv rdf:type xxx.) -> this one was not mentioned in the lecture, but is a very important one. \n",
    "*     (rdfs11) If G contains the triples (uuu rdfs:subClassOf vvv.) and (vvv rdfs:subClassOf xxx.) then infer the triple (uuu rdfs:subClassOf xxx.)\n",
    "\n",
    "\n",
    "Run your rule reasoner on your knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rdfs 7)  http://example.com/kad/Netherlands ex:closeBy http://example.com/kad/Belgium\n",
      "(rdfs 9)  http://example.com/kad/Germany rdf:type http://example.com/kad/Country\n",
      "(rdfs 11)  http://example.com/kad/EuropeanCountry rdfs:subClassOf http://example.com/kad/Location\n",
      "(rdfs 3)  http://example.com/kad/Germany rdf:type http://example.com/kad/Location\n",
      "(rdfs 2)  http://example.com/kad/Netherlands rdf:type http://example.com/kad/Country\n",
      "(rdfs 3)  http://example.com/kad/Rotterdam rdf:type http://example.com/kad/City\n",
      "(rdfs 5)  http://example.com/kad/hasCapital rdfs:subPropertyOf http://example.com/kad/contains\n",
      "(rdfs 7)  http://example.com/kad/Netherlands ex:containsCity http://example.com/kad/Amsterdam\n",
      "(rdfs 7)  http://example.com/kad/Germany ex:containsCity http://example.com/kad/Berlin\n",
      "(rdfs 9)  http://example.com/kad/Netherlands rdf:type http://example.com/kad/Location\n",
      "(rdfs 9)  http://example.com/kad/Belgium rdf:type http://example.com/kad/Location\n",
      "(rdfs 2)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/Location\n",
      "(rdfs 3)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/Capital\n",
      "(rdfs 3)  http://example.com/kad/Berlin rdf:type http://example.com/kad/Capital\n",
      "(rdfs 9)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/City\n",
      "(rdfs 11)  http://example.com/kad/Capital rdfs:subClassOf http://example.com/kad/Location\n",
      "(rdfs 7)  http://example.com/kad/Netherlands ex:contains http://example.com/kad/Rotterdam\n",
      "---------------------------------\n",
      "Number of inferred triples: 17\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "def myRDFSreasoner(myGraph):\n",
    "    inferredTriples = 0\n",
    "    for sbj, prd, obj in myGraph:\n",
    "\n",
    "        # --- rdfs2 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#domain\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 2) \", s, \"rdf:type\", obj)\n",
    "        \n",
    "        # --- rdfs3 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#range\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 3) \", o, \"rdf:type\", obj)\n",
    "\n",
    "        # --- rdfs5 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\"))):\n",
    "            generator = myGraph.predicate_objects(URIRef(obj))\n",
    "            for p, o in generator:\n",
    "                if (p.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\"))):\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 5) \", sbj, \"rdfs:subPropertyOf\", o)\n",
    "        \n",
    "        # --- rdfs7 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 7) \", s, \"ex:\" + obj.split(\"/\")[-1], o)\n",
    "        \n",
    "        # --- rdfs9 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"))):\n",
    "            generator = myGraph.subject_predicates(URIRef(sbj))\n",
    "            for s, p in generator:\n",
    "                if (p.eq(URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"))):\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 9) \", s, \"rdf:type\", obj)\n",
    "        \n",
    "        # --- rdfs11 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"))):\n",
    "            generator = myGraph.predicate_objects(URIRef(obj))\n",
    "            for p, o in generator:\n",
    "                if (p.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"))):\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 11) \", sbj, \"rdfs:subClassOf\", o)\n",
    "        \n",
    "        \n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Number of inferred triples:\", inferredTriples)\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "myRDFSreasoner(g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: (2 points) Build your very own RDFS knowledge graph. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a small RDF Schema vocabulary in Turtle. You can choose your own domain (e.g. movies, geography, sports) respecting all the following rules:\n",
    "*\tThe schema should define at least 4 classes, 4 properties, and 4 instances.\n",
    "*   The properties should be used to relate the instances\n",
    "*\tThe instances should be a member of your classes\n",
    "*\tAll resources should have an rdfs:label in a suitable language.\n",
    "\n",
    "You should use (at least) the following language features of RDF and RDFS:\n",
    "* \trdf:type (or 'a')\n",
    "* \trdfs:subClassOf\n",
    "* \trdfs:subPropertyOf\n",
    "* \trdfs:domain and rdfs:range\n",
    "*\trdfs:label\n",
    "\n",
    "Be sure to define the 'rdf:' and 'rdfs:' namespace prefixes for RDF and RDF Schema in your file (perhaps have a look at http://prefix.cc)\n",
    "\n",
    "For creating your vocabulary, you can either use a text editor, or add the axioms directly (programatically) to your Knowledge Graph as you did last week. \n",
    "\n",
    "Play around with the inference rules you have created in the previous task to make sure that you some added some implicit knowledge, that becomes \"visible\" via inferencing (this will be useful for the next task). \n",
    "\n",
    "Finally:\n",
    "- Add the knowledge you created into the RDFLIB graph datastructure *myRDFSgraph*, \n",
    "- Print *myRDFSgraph* in Turtle so that we can check your \"design\"\n",
    "- Save *myRDFSgraph* into a new file 'myRDFSgraph.ttl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now let's check what we can infer from your knowledge graph...\n",
      "The more rules you cover, the better!\n",
      "(rdfs 3)  http://example.com/kad/southAmerica rdf:type http://example.com/kad/location\n",
      "(rdfs 11)  http://example.com/kad/marsupial rdfs:subClassOf http://example.com/kad/animal\n",
      "(rdfs 9)  http://example.com/kad/giantPanda rdf:type http://example.com/kad/animal\n",
      "(rdfs 9)  http://example.com/kad/whaleShark rdf:type http://example.com/kad/animal\n",
      "(rdfs 7)  http://example.com/kad/koala ex:livesIn http://example.com/kad/australia\n",
      "(rdfs 2)  http://example.com/kad/whaleShark rdf:type http://example.com/kad/animal\n",
      "(rdfs 2)  http://example.com/kad/tarantula rdf:type http://example.com/kad/animal\n",
      "(rdfs 5)  http://example.com/kad/nationalAnimalOf rdfs:subPropertyOf http://example.com/kad/livesIn\n",
      "(rdfs 7)  http://example.com/kad/giantPanda ex:nativeOf http://example.com/kad/china\n",
      "---------------------------------\n",
      "Number of inferred triples: 9\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N4e3729fb95a34e57b77a5dfc48cefb39 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRDFSgraph = Graph()\n",
    "\n",
    "# Your code here.\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "ex = Namespace(\"http://example.com/kad/\")\n",
    "dbo = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "\n",
    "myRDFSgraph.bind('ex', ex)\n",
    "myRDFSgraph.bind('rdf', rdf)\n",
    "myRDFSgraph.bind('rdfs', rdfs)\n",
    "\n",
    "myRDFSgraph.add((ex.animal, rdf.type, ex.Class))\n",
    "myRDFSgraph.add((ex.fish, rdfs.subClassOf, ex.animal))\n",
    "myRDFSgraph.add((ex.mammal, rdfs.subClassOf, ex.animal))\n",
    "myRDFSgraph.add((ex.marsupial, rdfs.subClassOf, ex.mammal))\n",
    "\n",
    "myRDFSgraph.add((ex.livesIn, rdfs.range, ex.location))\n",
    "myRDFSgraph.add((ex.livesIn, rdfs.domain, ex.animal))\n",
    "myRDFSgraph.add((ex.hasDiet, rdfs.domain, ex.animal))\n",
    "\n",
    "myRDFSgraph.add((ex.nationalAnimalOf, rdfs.subPropertyOf, ex.nativeOf))\n",
    "myRDFSgraph.add((ex.nativeOf, rdfs.subPropertyOf, ex.livesIn))\n",
    "\n",
    "myRDFSgraph.add((ex.giantPanda, rdfs.label, Literal(\"Giant panda\", lang=\"en\")))\n",
    "myRDFSgraph.add((ex.giantPanda, rdf.type, ex.mammal))\n",
    "myRDFSgraph.add((ex.giantPanda, ex.nationalAnimalOf, ex.china))\n",
    "\n",
    "myRDFSgraph.add((ex.whaleShark, rdf.type, ex.fish))\n",
    "myRDFSgraph.add((ex.whaleShark, rdfs.label, Literal(\"Whale shark\", lang=\"en\")))\n",
    "myRDFSgraph.add((ex.whaleShark, ex.hasDiet, ex.plankton))\n",
    "\n",
    "myRDFSgraph.add((ex.koala, rdfs.label, Literal(\"Koala\", lang=\"en\")))\n",
    "myRDFSgraph.add((ex.koala, rdf.type, ex.Marsupial))\n",
    "myRDFSgraph.add((ex.koala, ex.nativeOf, ex.australia))\n",
    "\n",
    "myRDFSgraph.add((ex.tarantula, rdfs.label, Literal(\"Tarantula\", lang=\"en\")))\n",
    "myRDFSgraph.add((ex.tarantula, ex.livesIn, ex.southAmerica))\n",
    "\n",
    "print(\"Now let's check what we can infer from your knowledge graph...\")\n",
    "print(\"The more rules you cover, the better!\")\n",
    "myRDFSreasoner(myRDFSgraph)\n",
    "\n",
    "myRDFSgraph.serialize(destination=\"myRDFSgraph.ttl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (2 points) Compare local inferences with GraphDB results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload *myRDFSgraph.ttl* to GraphDB (check [the GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md) before starting to work with GraphDB).\n",
    "\n",
    "Formulate two different SPARQL queries, and write a Python code that executes these queries over your GraphDB SPARQL endpoint (check example of Task 1).\n",
    "\n",
    "**Each SPARQL query should return a different type of inferred knowledge** (at least one triple that was not explicitly asserted in the graph).\n",
    "\n",
    "Specify below next to your query, which type of RDFS rule is the GraphDB reasoner using to infer this answer (rdfs2, rdfs3, rdfs5, rdfs7, rdfs9, rdfs11). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your GraphDB repository URL (setup -> repositories -> repository url) and assign it to the variable 'myEndpoint' below. \n",
    "# It should be similar to this: \n",
    "\n",
    "myEndpoint = \"http://DESKTOP-DMHOCIP:7200/repositories/KnowledgeAndData\"  # KnowledgeAndData is the name of the repository\n",
    "sparql = SPARQLWrapper(myEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/giantPanda lives in http://example.com/kad/china\n",
      "http://example.com/kad/koala lives in http://example.com/kad/australia\n",
      "http://example.com/kad/tarantula lives in http://example.com/kad/southAmerica\n"
     ]
    }
   ],
   "source": [
    "# Query 1 - Specify which RDFS rule are you testing: \n",
    "# I am testing rdfs7 (for koala) and rdfs5 (and rdfs7) (for panda)\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX ex: <http://example.com/kad/>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    SELECT DISTINCT ?animalName ?location\n",
    "    WHERE {\n",
    "        ?animalName ex:livesIn ?location\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"animalName\"][\"value\"], \"lives in\", result[\"location\"][\"value\"]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/giantPanda\n",
      "http://example.com/kad/koala\n",
      "http://example.com/kad/tarantula\n",
      "http://example.com/kad/whaleShark\n"
     ]
    }
   ],
   "source": [
    "# Query 2 - Specify which RDFS rule are you testing: \n",
    "# I am testing rdfs11 (koala) and rdfs9 (panda and whaleshark)\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX ex: <http://example.com/kad/>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    SELECT DISTINCT ?animalName\n",
    "    WHERE {\n",
    "        ?animalName rdf:type ex:animal\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"animalName\"][\"value\"]) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
